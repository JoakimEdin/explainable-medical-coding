name: PLM-ICD Hyperparameter Sweep | MIMIC-III 50 Code | adversarial training bce alpha
program: train_plm.py
method: random
early_terminate:
    type: hyperband
    min_iter: 5
    eta: 0.8
metric:
  name: validation.f1_micro_tuned
  goal: maximize
parameters:
  experiment:
    value: mimiciii_50/plm_icd
  optimizer:
    value: adamw
  lr_scheduler:
    value: warmup_linear_decay
  loss:
    value: advesarial_training_loss
  trainer.epochs:
    value: 20
  trainer.threshold_tuning:
    value: true
  trainer.validate_on_training_data:
    value: false
  data.max_length:
    value: 6000
  dataloader.max_batch_size:
    value: 2
  optimizer.configs.lr:
    value: 5e-5
  optimizer.configs.weight_decay:
    value: 0
  loss.configs.lambda_1:
    value: 1e-2
  loss.configs.alpha:
    values: [1, 0.1, 0.01]
  loss.configs.lambda_2:
    value: 0.5
  loss.configs.epsilon:
    values: [1e-2, 1e-3]
  loss.configs.attack_type:
    value: pgd
  loss.configs.adv_dist:
    value: none







command:
  - ${env}
  - python
  - ${program}
  - gpu=-1
  - ${args_no_hyphens}
